{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Professor GitHub Repository](https://github.com/bardhprenkaj/ML_labs/blob/main/resources/project/project_description.pdf)\n",
    "\n",
    "[Project GitHub Repository](https://github.com/Naxetee/ML_FinalProject)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "During this first task we will apply some **pre-processing** operations to our raw data. So we will directly modify the data in *data/dataset/*, so that the data in *data/dataset_fixed/* will always remain unmodified."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, let's read the **.csv** files using a *pandas* function called **read_csv** whose parameters are:\n",
    "- *filepath*: the path of the .csv files.\n",
    "- *header*: will be always 0 to skip the columns' name row.\n",
    "- *names*: gives a name to each column of the table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../data/dataset/sample\"\n",
    "\n",
    "ap = pd.read_csv(data_path+'/anagraficapazientiattivi.csv', header=0 ,names=['idcentro','idana','sesso','annodiagnosidiabete','tipodiabete','scolarita','statocivile','professione','origine','annonascita','annoprimoaccesso','annodecesso'])\n",
    "diag = pd.read_csv(data_path+'/diagnosi.csv', header=0 ,names=['idcentro','idana','data','codiceamd','valore'])\n",
    "elp  = pd.read_csv(data_path+'/esamilaboratorioparametri.csv', header=0 ,names=['idcentro','idana','data','codiceamd','valore'])\n",
    "ei = pd.read_csv(data_path+'/esamistrumentali.csv', header=0 ,names=['idcentro','idana','data','codiceamd','valore'])\n",
    "pdf = pd.read_csv(data_path+'/prescrizionidiabetefarmaci.csv', header=0 ,names=['idcentro','idana','data','codiceatc','quantita','idpasto','descrizionefarmaco'])\n",
    "pdnf = pd.read_csv(data_path+'/prescrizionidiabetenonfarmaci.csv', header=0 ,names=['idcentro','idana','data','codiceamd','valore'])\n",
    "pnd = pd.read_csv(data_path+'/prescrizioninondiabete.csv', header=0 ,names=['idcentro','idana','data','codiceamd','valore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display example observations\n",
    "print(ap.shape)\n",
    "ap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diag.shape)\n",
    "diag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elp.shape)\n",
    "elp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ei.shape)\n",
    "ei.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdf.shape)\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pdnf.shape)\n",
    "pdnf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pnd.shape)\n",
    "pnd.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select Events of Interest -**\n",
    "We want only patients with at leats one cardiovascular event in their trajectories. These events have the folloging codes:\n",
    "- **AMD047**: Myocardial infarction\n",
    "- **AMD048**: Coronary angioplasty\n",
    "- **AMD049**: Coronary bypass\n",
    "- **AMD071**: Ictus\n",
    "- **AMD081**: Lower limb angioplasty\n",
    "- **AMD082**: Peripheral By-pass Lower Limbs\n",
    "- **AMD208**: Revascularization of intracranial and neck vessels\n",
    "- **AMD303**: Ischemic stroke\n",
    "\n",
    "Now let's try to filter all the tables containing the parameter **codiceamd** so as to select just the rows describing one cardio-vascular event.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = ['AMD047', 'AMD048', 'AMD049', 'AMD071', 'AMD081', 'AMD082', 'AMD208', 'AMD303']\n",
    "\n",
    "def selectEvents(df, events_codes) -> pd.DataFrame:\n",
    "    return df[df.codiceamd.isin(events_codes)]\n",
    "\n",
    "## pnd_cardEvents = selectEvents(pnd,codes)\n",
    "\n",
    "## pdnf_cardEvents = selectEvents(pdnf,codes)\n",
    "\n",
    "## ei_cardEvents = selectEvents(ei,codes)\n",
    "\n",
    "## elp_cardEvents = selectEvents(elp,codes)\n",
    "\n",
    "diag_cardEvents = selectEvents(diag,codes)\n",
    "print(\"BEFORE pre-processing: \", diag.shape)\n",
    "print(\"AFTER  pre-processing: \", diag_cardEvents.shape)\n",
    "diag_cardEvents.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realise that the only table with these cardio-vascular events is **diagnosi**, so we create a new DataFrame with all the rows that has one of these events, and we call it: **diag_cardEvents**. And from this table, we extract the id's of the patients that have suffered at least one cardio-vascular event during his life:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patientsOfInterest = diag_cardEvents.filter(['idcentro','idana']).drop_duplicates()\n",
    "print(\"Number of patients with at least one cardio-vascular event: \", patientsOfInterest.shape[0], \"/\", ap.shape[0] , \"patients.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to delete from the rest of the tables all the information which is not associated to the remaining patients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_ex1 = pd.merge(ap, patientsOfInterest, on=['idcentro','idana'], how='right')[ap.columns]\n",
    "diag_ex1 = pd.merge(diag, patientsOfInterest, on=['idcentro','idana'], how='right')[diag.columns]\n",
    "elp_ex1 = pd.merge(elp, patientsOfInterest, on=['idcentro','idana'], how='right')[elp.columns]\n",
    "ei_ex1 = pd.merge(ei, patientsOfInterest, on=['idcentro','idana'], how='right')[ei.columns]\n",
    "pdf_ex1 = pd.merge(pdf, patientsOfInterest, on=['idcentro','idana'], how='right')[pdf.columns]\n",
    "pdnf_ex1 = pd.merge(pdnf, patientsOfInterest, on=['idcentro','idana'], how='right')[pdnf.columns]\n",
    "pnd_ex1 = pd.merge(pnd, patientsOfInterest, on=['idcentro','idana'], how='right')[pnd.columns]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify the actual ranges of** ***esamilaboratorioparameteri*** **-** see this Table:\n",
    "\n",
    "| Code | Descriptive Name | True Range |\n",
    "|----------|----------|----------|\n",
    "| AMD004 | Systolic blood pressure | 40 <= x <= 200 |\n",
    "| AMD005 | Diastolic blood pressure | 40 <= x <= 130 |\n",
    "| AMD007 | Fasting blood glucose | 50 <= x <= 500 |\n",
    "| AMD008 | HbAlc | 5 <= x <= 15 |\n",
    "| AMD009 | Creatininemia | Not Available |\n",
    "| AMD111 | Microalbuminuria | Not Available |\n",
    "| STITCH001 | BMI | Not Available |\n",
    "| STITCH002 | LDL Choresterlo | 30 <= x <= 30|\n",
    "| STITCH003 | Non-HDL Cholesterlo | 60 <= x <= 330 |\n",
    "| STITCH004 | eGFR MDRD | Not Available |\n",
    "| STITCH005 | eGFR CKD-EPI | Not Available |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are doing is to use a **MinMaxScaler** from *sklearn* library so as to make the values described in the upper table fit into the true ranges. For the **NAN** ranges, we do nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "NAN = np.nan\n",
    "newRanges = [['AMD004', 'AMD005', 'AMD007', 'AMD008', 'AMD009', 'AMD111', 'STITCH001', 'STITCH002', 'STITCH003', 'STITCH004', 'STITCH005'],\n",
    "            [40.0,40.0,50.0,5.0,NAN,NAN,NAN,30.0,60.0,NAN,NAN],\n",
    "            [200.0,130.0,500.0,15.0,NAN,NAN,NAN,300.0,330.0,NAN,NAN]]\n",
    "\n",
    "def scaling(df, label, minValue, maxValue) -> pd.DataFrame:\n",
    "    if (minValue != NAN) and (maxValue != NAN) and (df[df.codiceamd == label].shape[0]>0):\n",
    "        aux = df[df.codiceamd == label].copy()\n",
    "        min_max_scaler = MinMaxScaler(feature_range=(minValue,maxValue))\n",
    "        aux[['valore']] = min_max_scaler.fit_transform(aux[['valore']])\n",
    "        df[df.codiceamd == label] = aux\n",
    "    return df\n",
    "\n",
    "\n",
    "# Let's apply the function to a new DataFrame copied from elp_new\n",
    "elp_ex4 = elp_ex1.copy()\n",
    "for k in range(len(newRanges[0])):\n",
    "    elp_ex4 = scaling(elp_ex4, newRanges[0][k], newRanges[1][k], newRanges[2][k])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we ensure manually that it has worked by printing the maximum and minimum values for each AMD Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['AMD004', 'AMD005', 'AMD007', 'AMD008', 'AMD009', 'AMD111', 'STITCH001', 'STITCH002', 'STITCH003', 'STITCH004', 'STITCH005']\n",
    "\n",
    "print(\"BEFORE RE-SCALING:\\n\")\n",
    "print(\"    AMD    Min  /  Max\")\n",
    "print(\"========================\")\n",
    "\n",
    "for label in labels:\n",
    "    aux = elp_ex1[elp_ex1.codiceamd == label].filter(['valore']).values.tolist()\n",
    "    if len(aux) > 0:\n",
    "        print(f\"{label}:    {np.min(aux):.1f} / {np.max(aux):.1f}\")\n",
    "    else:\n",
    "        print(f\"{label}:  is null\")\n",
    "\n",
    "print(\"\\n\\nAFTER RE-SCALING:\\n\")\n",
    "print(\"    AMD    Min  /  Max\")\n",
    "print(\"========================\")\n",
    "\n",
    "for label in labels:\n",
    "    aux = elp_ex4[elp_ex4.codiceamd == label].filter(['valore']).values.tolist()\n",
    "    if len(aux) > 0:\n",
    "        print(f\"{label}:    {np.min(aux):.1f} / {np.max(aux):.1f}\")\n",
    "    else:\n",
    "        print(f\"{label}:  is null\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it matches with the table given by the exercise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cohort selection and label definition** - use only those patients that after all the previous steps contain at least two events before calculating the label. Let $\\mathcal{P}=\\lbrace p_1, \\cdots,p_n\\rbrace$ be the set of all patients in the dataset. Let $d(e^i_k)$ be the date of the last event $e_k$ for patient $p_i\\in\\mathcal{P}$. The label of the patient $p_i$ is calculated as follows:\n",
    "\n",
    "$y(p_i)=\\begin{dcases}\n",
    "                1 & \\text{if, within }d(e^i_k)-6 \\text{ months, }p_i\\text{ has a cardiovascular event}\\\\\n",
    "                0 & \\text{otherwise}\n",
    "        \\end{dcases}$\n",
    "\n",
    "Eliminate the patients that have a trajectory shorten or equal to 6 months.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create a DataFrame that contains all the patients and their cardiovascular events, each one with its date (it's already computed as **diag_cardEvents**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_cardEvents.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each patient of the frame **diag_cardEvents**, we are going to take its two last cardiovascular events dates, so as to check if they happened with less than 6 months of difference. For this, we define the function **labeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(df) -> pd.DataFrame:\n",
    "\n",
    "    # First we define a dataframe that contains the ids and the dates of every cardiovascular event, sorted by descending date\n",
    "    cardEvents_sorted = df.sort_values('data',ascending=False)\n",
    "\n",
    "    # Now we create a new dataset called classes, that represents the result of the function y(p_i) defined previously:\n",
    "    classes = pd.DataFrame(columns=['idcentro','idana','class'])\n",
    "\n",
    "    # Now for each patient (idcentro,idana), we check if it verify the condition explained previously:\n",
    "    for label, subDataframe in cardEvents_sorted.groupby(['idcentro','idana']):\n",
    "\n",
    "        dates = subDataframe['data'].dropna().values\n",
    "\n",
    "        # We ignore those patients who have just one event\n",
    "        if len(dates) > 1:\n",
    "\n",
    "            # We extract the first and the 2 lastest dates and convert them into datetime objects\n",
    "            minDate = dates[-1]\n",
    "            maxDates = dates[0:2]\n",
    "            minDate = dt.date.fromisoformat(minDate)\n",
    "            maxDates = dt.date.fromisoformat(maxDates[0]), dt.date.fromisoformat(maxDates[1])\n",
    "\n",
    "            # We ignore patients with a trajectory shorter than 6 months (6*30 days)\n",
    "            if maxDates[0]-minDate > dt.timedelta(days=6*30):\n",
    "\n",
    "                # We calculate the difference between the latest 2 dates and compare it with 6 months\n",
    "                c = maxDates[0]-maxDates[1] < dt.timedelta(days=6*30)\n",
    "\n",
    "                # We add a new column with the label and the class of the patient\n",
    "                classes.loc[classes.count()[0]] = [label[0], label[1], int(c)]\n",
    "\n",
    "    return classes\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the **classes** dataframe, we have labeled the patients that have more than one event and a trajectory larger than 6 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labeling(diag_cardEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We still have: {labels.shape[0]}/{patientsOfInterest.shape[0]} patients\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we do an inner merge operation again with every dataframe to take just the patients of the frame **classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_ex5 = pd.merge(ap_ex2, labels, on=['idcentro','idana'], how='right')[ap_ex2.columns]\n",
    "diag_ex5 = pd.merge(diag_ex2, labels, on=['idcentro','idana'], how='right')[diag_ex2.columns]\n",
    "elp_ex5 = pd.merge(elp_ex4, labels, on=['idcentro','idana'], how='right')[elp_ex4.columns]\n",
    "ei_ex5 = pd.merge(ei_ex2, labels, on=['idcentro','idana'], how='right')[ei_ex2.columns]\n",
    "pdf_ex5 = pd.merge(pdf_ex2, labels, on=['idcentro','idana'], how='right')[pdf_ex2.columns]\n",
    "pdnf_ex5 = pd.merge(pdnf_ex2, labels, on=['idcentro','idana'], how='right')[pdnf_ex2.columns]\n",
    "pnd_ex5 = pd.merge(pnd_ex2, labels, on=['idcentro','idana'], how='right')[pnd_ex2.columns]\n",
    "patientsOfInterest_labeled = pd.merge(patientsOfInterest, labels, on=['idcentro','idana'], how='right')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
